---
title: Efficiency - Training (LoRA) and Inference(Quantization) (September 16)
---

### Slides: 

[Efficiency]({{ site.url }}/{{ site.baseurl }}/assets/slides/lecture3.pdf)

### Reading Material 
- LoRA: Low-Rank Adaptation of Large Language Models (2021) [[link](https://arxiv.org/abs/2106.09685)]

- LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale [[link](https://arxiv.org/abs/2208.07339)]

Optional readings:

- QLoRA: Efficient Finetuning of Quantized LLMs
 [[link](https://proceedings.neurips.cc/paper_files/paper/2023/hash/1feb87871436031bdc0f2beaa62a049b-Abstract-Conference.html)]

- LoRA+: Efficient Low Rank Adaptation of Large Models [[link](https://arxiv.org/abs/2402.12354)]

