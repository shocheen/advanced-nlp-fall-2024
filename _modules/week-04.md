---
title: Inference Algorithms (In-Context Learning and Chain-of-Thought) (September 23)
---

### Slides: 

[Inference Methods]({{ site.url }}/{{ site.baseurl }}/assets/slides/lecture4.pdf)

### Reading Material 
- Language Models are Few-Shot Learners [[link](https://arxiv.org/abs/2005.14165)]

- Chain-of-Thought Prompting Elicits Reasoning in Large Language Models [[link](https://arxiv.org/abs/2201.11903)]

Optional readings:

- Making Pre-trained Language Models Better Few-shot Learners (2021) [[link](https://arxiv.org/abs/2012.15723)]

- Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? (2022) [[link](https://aclanthology.org/2022.emnlp-main.759/)]

- Data Distributional Properties Drive Emergent In-Context Learning in Transformers (2022) [[link](https://arxiv.org/pdf/2205.05055)]

- Towards understanding chain-of-thought prompting: An empirical study of what matters (2022) [[link](https://arxiv.org/abs/2212.10001)]

- List of recent CoT papers (2024) [[link](https://github.com/Timothyxxx/Chain-of-ThoughtsPapers)]

