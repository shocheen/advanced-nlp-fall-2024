---
title: Instruction Following (September 30)
---

### Slides: 

[Instruction Following]({{ site.url }}/{{ site.baseurl }}/assets/slides/lecture5.pdf)

### Reading Material 
- Finetuned Language Models Are Zero-Shot Learners [[link](https://arxiv.org/abs/2109.01652)]

- Training language models to follow instructions with human feedback [[link](https://arxiv.org/abs/2203.02155)]

Optional readings:

- Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2 [[link](https://arxiv.org/abs/2311.10702)]

- The Llama 3 Herd of Models (Sec 4 and the relevant portion of Sec 5) [[link](https://arxiv.org/abs/2407.21783)]

- Fundamental Limitations of Alignment in Large Language Models [[link](https://arxiv.org/abs/2304.11082)]

- Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback [[link](https://arxiv.org/abs/2307.15217)]